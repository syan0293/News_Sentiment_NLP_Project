{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85aa3137-52d5-4e0f-9f42-3a3e3d4927d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\30796\\anaconda3\\lib\\site-packages (4.46.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\30796\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from transformers) (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\30796\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\30796\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: torch in c:\\users\\30796\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\30796\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\30796\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\30796\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\30796\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\30796\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab79740d-83ea-4a4a-a386-cf7a9e7a5683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           category                              title  \\\n",
      "0          business    UK house prices dip in November   \n",
      "1          business  LSE 'sets date for takeover deal'   \n",
      "2             sport    Harinordoquy suffers France axe   \n",
      "3          business  Barclays shares up on merger talk   \n",
      "4          politics   Campaign 'cold calls' questioned   \n",
      "...             ...                                ...   \n",
      "1552       business  Hariri killing hits Beirut shares   \n",
      "1553       politics  MPs issued with Blackberry threat   \n",
      "1554  entertainment  Bollywood DVD fraudster is jailed   \n",
      "1555          sport                Ireland v USA (Sat)   \n",
      "1556           tech  Row brewing over peer-to-peer ads   \n",
      "\n",
      "                                                content  \n",
      "0      UK house prices dipped slightly in November, ...  \n",
      "1      The London Stock Exchange (LSE) is planning t...  \n",
      "2      Number eight Imanol Harinordoquy has been dro...  \n",
      "3      Shares in UK banking group Barclays have rise...  \n",
      "4      Labour and the Conservatives are still teleph...  \n",
      "...                                                 ...  \n",
      "1552   Shares in Solidere, the Lebanese company foun...  \n",
      "1553   MPs will be thrown out of the Commons if they...  \n",
      "1554   A major distributor of pirated DVDs of Bollyw...  \n",
      "1555   Saturday 20 November  Lansdowne Road, Dublin ...  \n",
      "1556   Music download networks are proving popular n...  \n",
      "\n",
      "[1557 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('news-dataset.csv',sep='\\t')\n",
    "df=pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4a3a06-8dff-4917-88ff-72f2202d5e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X = df['content']\n",
    "y = df['category']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7a5611-0ad1-4f57-a806-bc7a289d3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_tokens = tokenizer(X_train.tolist(), padding='max_length', max_length=seq_len, truncation=True, return_tensors=\"pt\")\n",
    "val_tokens = tokenizer(X_val.tolist(), padding='max_length', max_length=seq_len, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "X_train_ids, X_train_mask = train_tokens['input_ids'], train_tokens['attention_mask']\n",
    "X_val_ids, X_val_mask = val_tokens['input_ids'], val_tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bcdc6a3-5c99-4644-b933-ebef4a99d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_ids, X_train_mask, torch.tensor(y_train_encoded, dtype=torch.long))\n",
    "val_dataset = TensorDataset(X_val_ids, X_val_mask, torch.tensor(y_val_encoded, dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a41a0dc-c246-42fe-8b8c-e7e64ac9b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "dbert_pt = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38178c41-ddf6-4051-a043-33e399d155ce",
   "metadata": {},
   "source": [
    "## Build an 2-layer classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e4b11e-ffde-4ced-8c18-d31792ec8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_classes):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "       \n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()  # Use ReLU activation function\n",
    "       \n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        # Output layer uses Softmax for classification\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)   \n",
    "        x = self.relu(x)  \n",
    "        x = self.fc2(x)  \n",
    "        x = self.softmax(x)  \n",
    "        return x\n",
    "\n",
    "embedding_dim = 768  # Embedding dimension from DistilBERT\n",
    "hidden_dim = 128     # Dimension of the hidden layer, adjustable parameter\n",
    "num_classes = 5      # Number of classes to predict\n",
    "classifier = SimpleClassifier(embedding_dim, hidden_dim, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250c418-68d0-4066-819a-a58c209e2247",
   "metadata": {},
   "source": [
    "## adjuist the Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "805e2983-c346-4d8b-b542-f837d06c4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4 \n",
    "batch_size = 16       \n",
    "epochs = 10\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238499d1-ece8-41c2-9f16-7aebfad187b0",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9123aaf-96e7-42f3-9d5d-abea093cdb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.5604\n",
      "Epoch 2/10, Train Loss: 1.4201\n",
      "Epoch 3/10, Train Loss: 1.2698\n",
      "Epoch 4/10, Train Loss: 1.1670\n",
      "Epoch 5/10, Train Loss: 1.0945\n",
      "Epoch 6/10, Train Loss: 1.0481\n",
      "Epoch 7/10, Train Loss: 1.0213\n",
      "Epoch 8/10, Train Loss: 1.0037\n",
      "Epoch 9/10, Train Loss: 0.9917\n",
      "Epoch 10/10, Train Loss: 0.9828\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    classifier.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        X_batch, mask_batch, labels_batch = batch\n",
    "        outputs = dbert_pt(X_batch, attention_mask=mask_batch)\n",
    "        hidden_X = outputs['last_hidden_state']\n",
    "    \n",
    "        input_embedding = hidden_X[:, 0, :]\n",
    "        input_embedding = input_embedding.float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = classifier(input_embedding)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {total_train_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e99662-98df-4f97-8402-c9bf9a1bdf6a",
   "metadata": {},
   "source": [
    "## evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d3c9d7c-c8f0-4033-b71b-a77ce0ab2baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.98      0.91      0.95        68\n",
      "entertainment       0.88      0.95      0.91        39\n",
      "     politics       0.94      0.98      0.96        59\n",
      "        sport       0.96      1.00      0.98        80\n",
      "         tech       0.96      0.90      0.93        58\n",
      "\n",
      "     accuracy                           0.95       304\n",
      "    macro avg       0.95      0.95      0.95       304\n",
      " weighted avg       0.95      0.95      0.95       304\n",
      "\n",
      "Weighted F1-score: 0.9505\n"
     ]
    }
   ],
   "source": [
    "classifier.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs, masks, labels = batch\n",
    "        \n",
    "        outputs = dbert_pt(inputs, attention_mask=masks)\n",
    "        hidden_X = outputs['last_hidden_state']\n",
    "        \n",
    "        input_embedding = hidden_X[:, 0, :] \n",
    "        input_embedding = input_embedding.float()  \n",
    "\n",
    "        outputs = classifier(input_embedding)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=['business', 'entertainment', 'politics', 'sport', 'tech']))\n",
    "\n",
    "weighted_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "print(f'Weighted F1-score: {weighted_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb42714-5278-4fc2-9c54-af2f3139d93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9977bbc-a6a7-4e79-9d66-886229afb6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
